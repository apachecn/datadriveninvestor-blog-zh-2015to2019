# ä»é›¶å¼€å§‹å›å½’â€”â€”è‘¡è„é…’è´¨é‡é¢„æµ‹

> åŸæ–‡ï¼š<https://medium.datadriveninvestor.com/regression-from-scratch-wine-quality-prediction-d61195cb91c8?source=collection_archive---------0----------------------->

[![](img/3a20e4a34d9613f7d153dfbced04f7f3.png)](http://www.track.datadriveninvestor.com/1B9E)![](img/2d9a63c379aa8fc0497be7fb6a96daf3.png)

Photo by [Ryan Hutton](https://unsplash.com/photos/Jztmx9yqjBw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘ä¹‹å‰å…³äºæœºå™¨å­¦ä¹ çš„ä¸‰ç¯‡æ–‡ç« çš„ç³»åˆ—ï¼Œåœ¨é‚£ä¸‰ç¯‡æ–‡ç« ä¸­æˆ‘ä»¬è®¨è®ºäº†åŸºç¡€çŸ¥è¯†ã€å›å½’å’Œåˆ†ç±»ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ç ”ç©¶ä¸€ä¸ªå…³äºå›å½’çš„å°é¡¹ç›®ï¼Œå®ƒå°†å¸®åŠ©åˆå­¦è€…å¼€å§‹æœºå™¨å­¦ä¹ ã€‚ä½ éœ€è¦ä¸€ä¸ªå°æ—¶æ¥è®¾ç½®ã€ç†è§£å’Œç¼–ç ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å¼€å§‹å§ğŸ˜ƒ

[](https://medium.com/datadriveninvestor/beginning-with-machine-learning-56b076aace1e) [## ä»æœºå™¨å­¦ä¹ å¼€å§‹

### å‡ ä¹æ¯ä¸ªæƒ³ç©è¿™é¡¹æ–°æŠ€æœ¯çš„äººéƒ½ä¼šæƒ³åˆ°è¿™ä¸ªé—®é¢˜ã€‚æˆ‘è‡ªå·±ä¹Ÿæƒ³çŸ¥é“â€¦

medium.com](https://medium.com/datadriveninvestor/beginning-with-machine-learning-56b076aace1e) [](https://medium.com/datadriveninvestor/regression-in-machine-learning-296caae933ec) [## æœºå™¨å­¦ä¹ ä¸­çš„å›å½’

### å›å½’æ¨¡å‹ç”¨äºé¢„æµ‹è¿ç»­å€¼ã€‚ç»™å®šæˆ¿å­çš„ç‰¹å¾ï¼Œé¢„æµ‹æˆ¿å­çš„ä»·æ ¼ï¼Œå¦‚â€¦

medium.com](https://medium.com/datadriveninvestor/regression-in-machine-learning-296caae933ec) [](https://medium.com/datadriveninvestor/classification-in-machine-learning-db33514c77ad) [## æœºå™¨å­¦ä¹ ä¸­çš„åˆ†ç±»

### åˆ†ç±»ç”¨äºå¯¹ä¸åŒçš„å¯¹è±¡è¿›è¡Œåˆ†ç±»ã€‚æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ç›‘ç£é—®é¢˜(å°±åƒâ€¦

medium.com](https://medium.com/datadriveninvestor/classification-in-machine-learning-db33514c77ad) 

# è‘¡è„é…’è´¨é‡é¢„æµ‹

![](img/706121a65e5e7ed6d41f51774b577cc8.png)

è¿™é‡Œçš„ä»»åŠ¡æ˜¯*ç»™å®šä¸€ç»„ç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œåœ¨ 0-10 çš„èŒƒå›´å†…é¢„æµ‹çº¢é…’*çš„è´¨é‡ã€‚æˆ‘å·²ç»ç”¨ ***çº¿æ€§å›å½’è§£å†³äº†å®ƒä½œä¸ºä¸€ä¸ªå›å½’é—®é¢˜ã€‚***

ä½¿ç”¨çš„æ•°æ®é›†æ˜¯æ¥è‡ª UCI æœºå™¨å­¦ä¹ çŸ¥è¯†åº“çš„è‘¡è„é…’è´¨é‡æ•°æ®é›†ã€‚[https://archive.ics.uci.edu/ml/datasets/Wine+Quality](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)

è¾“å…¥å˜é‡ä¸ºå›ºå®šé…¸åº¦ã€æŒ¥å‘æ€§é…¸åº¦ã€æŸ æª¬é…¸ã€æ®‹ç³–ã€æ°¯åŒ–ç‰©ã€æ¸¸ç¦»äºŒæ°§åŒ–ç¡«ã€æ€»äºŒæ°§åŒ–ç¡«ã€å¯†åº¦ã€pHã€ç¡«é…¸ç›ã€é…’ç²¾ã€‚å¹¶ä¸”è¾“å‡ºå˜é‡(åŸºäºæ„Ÿå®˜æ•°æ®)æ˜¯è´¨é‡(å¾—åˆ†åœ¨ 0 åˆ° 10 ä¹‹é—´)ã€‚ä¸‹é¢æ˜¯æ•°æ®é›†å‰ 5 è¡Œçš„å±å¹•æˆªå›¾ã€‚

![](img/c26f94930cb51a44c2574191e7b5edad.png)

Top 5 rows of Wine Quality dataset

# å±å›½

ä»£ç æ˜¯ç”¨ python å†™çš„ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¯·ä½¿ç”¨ pip å®‰è£…ä»¥ä¸‹åº“ã€‚

1.  ç†ŠçŒ«:pip å®‰è£…ç†ŠçŒ«
2.  matplotlib: pip å®‰è£… matplotlib
3.  å®‰è£…
4.  scikit-learn: pip å®‰è£… scikit-learn

å°±æ˜¯è¿™æ ·ï¼ä½ å·²ç»å®Œæˆä¸€åŠäº†ğŸ˜„ã€‚æ¥ä¸‹æ¥ï¼ŒæŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤ï¼Œä»¥å»ºç«‹ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹åœ¨ä»»ä½•æ—¶å€™ï¼

# æ–¹æ³•

åˆ›å»ºä¸€ä¸ªæ–°çš„ IPython ç¬”è®°æœ¬ï¼Œæ’å…¥ä¸‹é¢çš„ä»£ç æ¥å¯¼å…¥å¿…è¦çš„æ¨¡å—ã€‚å¦‚æœæ‚¨é‡åˆ°ä»»ä½•é”™è¯¯ï¼Œè¯·ä½¿ç”¨ pip å®‰è£…å¿…è¦çš„è½¯ä»¶åŒ…ã€‚

```
import pandas as pd 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression 
from sklearn import metrics 
import matplotlib.pyplot as plt 
import numpy as np 
import seaborn as sns
```

ä½¿ç”¨ pandas å°†æ•°æ®è¯»å…¥æ•°æ®å¸§ã€‚è¦æ£€æŸ¥æ•°æ®é›†çš„å‰ 5 è¡Œï¼Œä½¿ç”¨`df.head()`

```
df = pd.read_csv('winequality-red.csv')
df.head()
```

ä½¿ç”¨`corr()`æŸ¥æ‰¾æ•°æ®é›†æ¯ä¸ªå±æ€§ä¹‹é—´çš„ç›¸å…³æ€§

```
***# there are no categorical variables. each feature is a number. Regression problem.* 
*# Given the set of values for features, we have to predict the quality of wine. finding correlation of each feature with our target variable - quality***
correlations = df.corr()['quality'].drop('quality')
print(correlations)
```

![](img/fbf9b9bfff40d259b9a152873fc989f0.png)

Correlations between each attribute and target variable â€” quality

è¦ç»˜åˆ¶çƒ­å›¾å¹¶è·å¾—è¯¦ç»†çš„å…³è”å›¾ï¼Œè¯·æ’å…¥ä»¥ä¸‹ä»£ç ã€‚

```
sns.heatmap(df.corr())
plt.show()
```

![](img/a0a23fd324da4a84083e68fc2bbc8820.png)

Heatmap

å®šä¹‰ä¸€ä¸ªå‡½æ•°`get_features()`ï¼Œè¯¥å‡½æ•°åªè¾“å‡ºé‚£äº›ç›¸å…³æ€§é«˜äºé˜ˆå€¼çš„ç‰¹å¾(ä½œä¸ºè¾“å…¥å‚æ•°ä¼ é€’ç»™å‡½æ•°)ã€‚

```
**def** get_features(correlation_threshold):
    abs_corrs = correlations.abs()
    high_correlations = abs_corrs
    [abs_corrs > correlation_threshold].index.values.tolist()
    **return** high_correlations
```

åˆ›å»ºåŒ…å«è¾“å…¥ç‰¹å¾çš„å‘é‡`x`å’ŒåŒ…å«è´¨é‡å˜é‡çš„å‘é‡`y`ã€‚åœ¨`x`æˆ‘ä»¬å¾—åˆ°äº†é™¤æ®‹ç³–ä»¥å¤–çš„æ‰€æœ‰ç‰¹å¾ã€‚å¦‚æœä½ æ„¿æ„ï¼Œé˜ˆå€¼å¯ä»¥å¢åŠ ã€‚

```
***#******taking features with correlation more than 0.05 as input x and quality as target variable y*** 
features = get_features(0.05) 
print(features) 
x = df[features] 
y = df['quality']
```

ä½¿ç”¨`train_test_split`åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•é›†ã€‚25%çš„æ•°æ®ç”¨äºæµ‹è¯•ï¼Œ75%ç”¨äºè®­ç»ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨`x_train.shape`æ£€æŸ¥æ•°æ®é›†çš„å¤§å°

```
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=3)
```

åˆ›å»ºæ•°æ®é›†åï¼Œå°±è¯¥æ„å»ºçº¿æ€§å›å½’æ¨¡å‹äº†ã€‚æ‚¨å¯ä»¥ç®€å•åœ°ä½¿ç”¨å†…ç½®å‡½æ•°æ¥åˆ›å»ºæ¨¡å‹ï¼Œç„¶åæ ¹æ®è®­ç»ƒæ•°æ®è¿›è¡Œæ‹Ÿåˆã€‚ä¸€æ—¦è®­ç»ƒå®Œæ¯•ï¼Œ`coef_`ç»™å‡ºæ¯ä¸ªç‰¹å¾çš„ç³»æ•°å€¼ã€‚

```
***# fitting linear regression to training data***
regressor = LinearRegression()
regressor.fit(x_train,y_train)
  ***# this gives the coefficients of the 10 features selected above. *** print(regressor.coef_)
```

ç”¨è¿™ä¸ªæ¨¡å‹é¢„æµ‹è‘¡è„é…’çš„è´¨é‡ï¼Œç”¨`predict()`ã€‚

```
train_pred = regressor.predict(x_train)
print(train_pred)
test_pred = regressor.predict(x_test) 
print(test_pred)
```

è®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å‡æ–¹æ ¹è¯¯å·®ã€‚*å‡æ–¹æ ¹è¯¯å·®(RMSE)æ˜¯æ¨¡å‹é¢„æµ‹å€¼(æ ·æœ¬å€¼å’Œæ€»ä½“å€¼)ä¸å®é™…è§‚å¯Ÿå€¼ä¹‹é—´å·®å¼‚çš„å¸¸ç”¨åº¦é‡ã€‚å¦‚æœæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¥½çš„æ¨¡å‹ï¼Œé‚£ä¹ˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ RMSE åº”è¯¥éå¸¸ç›¸ä¼¼ã€‚å¦‚æœæµ‹è¯•é›†çš„ RMSE æ¯”è®­ç»ƒé›†çš„é«˜å¾—å¤šï¼Œå¾ˆå¯èƒ½æˆ‘ä»¬ä¸¥é‡åœ°è¿‡åº¦æ‹Ÿåˆäº†æ•°æ®ã€‚*

```
**# calculating rmse**
train_rmse = mean_squared_error(train_pred, y_train) ** 0.5
print(train_rmse)
test_rmse = mean_squared_error(test_pred, y_test) ** 0.5
print(test_rmse)***# rounding off the predicted values for test set***
predicted_data = np.round_(test_pred)
print(predicted_data)print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, test_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, test_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, test_pred)))**# displaying coefficients of each feature**
coeffecients = pd.DataFrame(regressor.coef_,features) coeffecients.columns = ['Coeffecient'] 
print(coeffecients)
```

![](img/e07292faff6f905e0c6b29a71b5087d0.png)

Coefficients of each feature

***è¿™äº›æ•°å­—æ„å‘³ç€åœ¨æ‰€æœ‰å…¶ä»–ç‰¹å¾ä¸å˜çš„æƒ…å†µä¸‹ï¼Œç¡«é…¸ç›æ¯å¢åŠ  1 ä¸ªå•ä½ï¼Œè‘¡è„é…’çš„è´¨é‡å°±ä¼šå¢åŠ  0.8ï¼Œå…¶ä»–ç‰¹å¾ä¹Ÿæ˜¯å¦‚æ­¤ã€‚*
*åŒæ ·åœ¨å…¶ä»–æ‰€æœ‰ç‰¹å¾ä¸å˜çš„æƒ…å†µä¸‹ï¼ŒæŒ¥å‘æ€§é…¸åº¦å¢åŠ  1 ä¸ªå•ä½ä¼šå¯¼è‡´è‘¡è„é…’è´¨é‡ä¸‹é™ 0.99ï¼Œå…¶ä»–ç‰¹å¾ä¹Ÿæ˜¯å¦‚æ­¤ã€‚***

å› æ­¤ï¼Œé€šè¿‡å‡ è¡Œä»£ç ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ„å»ºä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹æ¥é¢„æµ‹è‘¡è„é…’çš„è´¨é‡ï¼Œå¯¹äºè®­ç»ƒé›† ***å’Œæµ‹è¯•é›†*** æ¥è¯´ï¼ŒRMSE åˆ†æ•°åˆ†åˆ«ä¸º 0.65 å’Œ 0.63ã€‚è¿™åªæ˜¯ä¸€ä¸ªå¸®åŠ©ä½ å¼€å§‹å›å½’çš„æƒ³æ³•ã€‚æ‚¨å¯ä»¥å°è¯•é˜ˆå€¼ã€å…¶ä»–å›å½’æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥å°è¯•ç‰¹å¾å·¥ç¨‹ğŸ˜ã€‚

è¦è·å¾—å®Œæ•´çš„ä»£ç ï¼Œè¯·ä½¿ç”¨ä¸‹é¢çš„é“¾æ¥åˆ°æˆ‘çš„ä»“åº“ã€‚æ•°æ®é›†ä¹Ÿè¢«ä¸Šä¼ :)å…‹éš†å­˜å‚¨åº“å¹¶è¿è¡Œç¬”è®°æœ¬æ¥æŸ¥çœ‹ç»“æœã€‚

[](https://github.com/apoorva-dave/WineQualityPrediction) [## apoorva-Dave/è‘¡è„é…’è´¨é‡é¢„æµ‹

### é¢„æµ‹è‘¡è„é…’çš„è´¨é‡ã€‚é€šè¿‡åœ¨ä»¥ä¸‹ç½‘ç«™åˆ›å»ºè´¦æˆ·ï¼Œä¸º apoorva-Dave/wine quality prediction çš„å‘å±•åšå‡ºè´¡çŒ®

github.com](https://github.com/apoorva-dave/WineQualityPrediction) 

ä¸‹ä¸€ç¯‡æ–‡ç« å°†æ˜¯ä¸€ä¸ªç±»ä¼¼çš„å…³äºåˆ†ç±»çš„å°é¡¹ç›®ã€‚å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œä¸€å®šè¦å±•ç¤ºä¸€äº›â¤ï¼Œè¯·ç»§ç»­å…³æ³¨ï¼åœ¨é‚£ä¹‹å‰ï¼Œç¥ä½ å­¦ä¹ æ„‰å¿«ğŸ˜¸